{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is performing a dataset split, specifically for organizing MIDI song data into training, validation, and test sets. Hereâ€™s a breakdown of what each section of the code accomplishes:\n",
    "\n",
    "1. **Data Loading and Initial Setup**:\n",
    "   - The code loads the dataset from a CSV file (`metadata_by_song.csv`) and sets the `songID` column as the index. \n",
    "   - `create_split` function is defined to sample a fixed number of songs from each quality category (`DominantQ`).\n",
    "\n",
    "2. **Splitting into Test and Train/Validation Sets**:\n",
    "   - `create_split` is used to sample `song_num` songs (8, by default) randomly from each quality category (Q1, Q2, Q3, Q4).\n",
    "   - The result (`test_data`) is set aside as the test set, and the rest of the data (`train_val`) is retained for further splitting.\n",
    "\n",
    "3. **Creating Validation and Training Sets**:\n",
    "   - Another call to `create_split` generates the validation set (`val_data`) by sampling from `train_val`.\n",
    "   - The remaining data in `train_val` becomes the training set (`train_data`).\n",
    "   - The code ensures no overlap exists between the train, validation, and test sets, asserting their independence by checking indices.\n",
    "\n",
    "4. **Counting and Verifying Ratios**:\n",
    "   - The code calculates the total number of instances in each set for each quality category and verifies their relative ratios to assess the split distribution using `count_ratio`.\n",
    "\n",
    "5. **Saving Song-Level Splits**:\n",
    "   - Each split (train, validation, and test) is saved as a separate CSV file (`train_SL.csv`, `val_SL.csv`, `test_SL.csv`) for easy access.\n",
    "\n",
    "6. **Linking MIDI Files to Their Split Category**:\n",
    "   - The code scans the directory `data_root` (which contains the MIDI files) and links each MIDI file with its corresponding split (train, validation, or test) by comparing filenames to song IDs in `split_dict`.\n",
    "   - Based on this matching, MIDI file names are appended to `train_clips`, `val_clips`, or `test_clips` lists.\n",
    "\n",
    "7. **Saving Clip-Level Splits**:\n",
    "   - Finally, it saves the lists of MIDI filenames for each split into separate CSV files (`train_clip.csv`, `val_clip.csv`, `test_clip.csv`) to keep track of individual MIDI clips associated with each split.\n",
    "\n",
    "In summary, the code organizes and splits MIDI data into training, validation, and test datasets at both the song and clip levels, ensuring no overlap and creating a balanced distribution across quality categories. This setup would typically support machine learning tasks like classification or analysis on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../metadata_by_song.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m src_csv \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m../metadata_by_song.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(src_csv)\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(data\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      4\u001b[0m data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mset_index(\u001b[39m\"\u001b[39m\u001b[39msongID\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[39m=\u001b[39mioargs\u001b[39m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[39m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../metadata_by_song.csv'"
     ]
    }
   ],
   "source": [
    "src_csv = '../metadata_by_song.csv'\n",
    "data = pd.read_csv(src_csv)\n",
    "print(data.shape)\n",
    "data = data.set_index(\"songID\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_split(data, song_num=8, random_seed=1):\n",
    "    '''\n",
    "    Will return test data as an new dataframe.\n",
    "    Random sample song_num songs from each Q, \n",
    "    and the result of the number of clips will roughly be 1/10 in each Q.\n",
    "    '''\n",
    "    Q1 = data[data['DominantQ'] == 1]\n",
    "    Q2 = data[data['DominantQ'] == 2]\n",
    "    Q3 = data[data['DominantQ'] == 3]\n",
    "    Q4 = data[data['DominantQ'] == 4]\n",
    "    test_Q1 = Q1.sample(song_num, random_state=1)\n",
    "    test_Q2 = Q2.sample(song_num, random_state=1)\n",
    "    test_Q3 = Q3.sample(song_num, random_state=1)\n",
    "    test_Q4 = Q4.sample(song_num, random_state=1)\n",
    "    test_data = pd.concat([test_Q1, test_Q2, test_Q3, test_Q4])\n",
    "    print(test_data.sum(axis = 0))\n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_Q1       25\n",
      "num_Q2       19\n",
      "num_Q3       21\n",
      "num_Q4       23\n",
      "DominantQ    80\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "test_data = create_split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val = data.drop(labels = test_data.index, axis = 0, inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_Q1</th>\n",
       "      <th>num_Q2</th>\n",
       "      <th>num_Q3</th>\n",
       "      <th>num_Q4</th>\n",
       "      <th>DominantQ</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>songID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>e8NQ2NH0nc8</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HQ8ISDX6PiI</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZTrEoB8T9YA</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3N2G21U7guk</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_8v0MFBZoco</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             num_Q1  num_Q2  num_Q3  num_Q4  DominantQ\n",
       "songID                                                \n",
       "e8NQ2NH0nc8       2       0       0       0          1\n",
       "HQ8ISDX6PiI       0       0       0       2          4\n",
       "ZTrEoB8T9YA       0       3       0       0          2\n",
       "3N2G21U7guk       3       0       0       4          4\n",
       "_8v0MFBZoco       2       0       0       0          1"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_Q1       24\n",
      "num_Q2       30\n",
      "num_Q3       33\n",
      "num_Q4       27\n",
      "DominantQ    80\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "val_data = create_split(train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_val.drop(labels = val_data.index, axis = 0, inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure there is no song overlap between train, val, test\n",
    "assert len(set(train_data.index) & set(val_data.index)) == 0\n",
    "assert len(set(train_data.index) & set(test_data.index)) == 0\n",
    "assert len(set(test_data.index) & set(val_data.index)) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num = train_data.sum()\n",
    "val_num = val_data.sum()\n",
    "test_num = test_data.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_ratio(nums, Q=1):\n",
    "    total = sum([x['num_Q'+str(Q)] for x in nums])\n",
    "    print('train: {}'.format(nums[0]['num_Q'+ str(Q)] / total))\n",
    "    print('val  : {}'.format(nums[1]['num_Q'+ str(Q)] / total))\n",
    "    print('test : {}'.format(nums[2]['num_Q'+ str(Q)] / total))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 0.804\n",
      "val  : 0.096\n",
      "test : 0.1\n"
     ]
    }
   ],
   "source": [
    "nums = [train_num, val_num, test_num]\n",
    "count_ratio(nums, Q=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save song level split\n",
    "os.makedirs('../split', exist_ok=True)\n",
    "\n",
    "train_data.to_csv('../split/train_SL.csv')\n",
    "val_data.to_csv('../split/val_SL.csv')\n",
    "test_data.to_csv('../split/test_SL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '../midis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_files = glob.glob(os.path.join(data_root, '*.mid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dict = {}\n",
    "for song in train_data.index:\n",
    "    split_dict[song] = 'train'\n",
    "for song in val_data.index:\n",
    "    split_dict[song] = 'val'\n",
    "for song in test_data.index:\n",
    "    split_dict[song] = 'test'\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# formatted as: ../midis/Q3_egYSmNuIFGk_1.mid\n",
    "\n",
    "train_clips = []\n",
    "val_clips = []\n",
    "test_clips = []\n",
    "\n",
    "for mid in midi_files:\n",
    "    filename = mid[9:]\n",
    "    # print(filename)\n",
    "    songname = filename[3:14]\n",
    "    # print(songname)\n",
    "    if split_dict[songname] == 'train':\n",
    "        train_clips.append(filename)\n",
    "    if split_dict[songname] == 'val':\n",
    "        val_clips.append(filename)\n",
    "    if split_dict[songname] == 'test':\n",
    "        test_clips.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the clip lists\n",
    "train_df = pd.DataFrame({'clip_name': train_clips})\n",
    "train_df.to_csv('../split/train_clip.csv')\n",
    "\n",
    "val_df = pd.DataFrame({'clip_name': val_clips})\n",
    "val_df.to_csv('../split/val_clip.csv')\n",
    "\n",
    "test_df = pd.DataFrame({'clip_name': test_clips})\n",
    "test_df.to_csv('../split/test_clip.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
